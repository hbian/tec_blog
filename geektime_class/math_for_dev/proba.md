## Proba and Statistic theory
概率（Probability）就是描述这种可能性的一个数值
我们用随机变量（Random Variable）来描述事件所有可能出现的状态，并使用概率分布（Probability Distribution）来描述每个状态出现的可能性。

概率分布P(x):
假设我们使用一个随机变量 x 来表示新闻类型，如果在 100 篇新闻中，有 60 篇是娱乐新闻，有 20 篇是科技新闻，有 20 篇是体育新闻，那么你看到娱乐新闻的概率就是 60%，看到科技新闻的概率就是 20%，看到体育新闻的概率就是 20%。而这三组数据就可以构成变量 x 的概率分布P(x)。

联合概率（Joint Probability）P(x,y):
在这个概率分布中，我们只有一个随机变量 x，现在我再添加另一个随机变量 y，表示新闻属于国际的还是国内的。这个时候，新的概率分布就需要由 x 和 y 这两个变量联合起来才能决定，我们把这种概率称为联合概率（Joint Probability）


其实概率论研究的就是这些概率之间相互转化的关系，比如联合概率、条件概率和边缘概率。

概率和统计其实是互逆的。怎么个互逆呢？概率论是对数据产生的过程进行建模，然后研究某种模型所产生的数据有什么特性。而统计学正好相反，它需要通过已知的数据，来推导产生这些数据的模型是怎样的。因此统计特别关注数据的各种分布、统计值及其对应的统计意义。

离散型随机变量和连续型随机变量:
抛硬币出现正反面的次数以及每周下雨的天数，都是离散的值，所以对应的随机变量为离散型。而汽车每小时行驶的速度和银行排队的时间，都是连续的值，对应的随机变量为连续型。换句话，从计算的角度来说，我们可以直接求和得出的，就是“离散的”，需要用积分计算的，就是“连续的”。

统计的采样次数越多，越趋近于我们理论上的情况,概率分布描述的其实就是随机变量的概率规律。

伯努利分布（Bernoulli Distribution）:
这是单个随机变量的分布，而且这个变量的取值只有两个，0 或 1。伯努利分布通过参数λ来控制这个变量为 1 的概率：
P(x=1) = λ
P(x=0) = 1-λ

之前抛硬币的概率分布就属于伯努利分布。 

分类分布（Categorical Distribution） Multinoulli 分布:
它描述了一个具有 k 个不同状态的单个随机变量。这里的 k，是有限的数值，如果 k 为 2 的时候，那么分类分布就变成了伯努利分布。
P(x=k) = λk
P(x=3) = λ3

离散型随机变量的状态数量是有限的，所以可以通过伯努利和分类分布来描述。可是对于连续型随机变量来说，状态是无穷多的，这时我们就需要连续分布模型。比较经典的连续分布有正态分布、均匀分布、指数分布、拉普拉斯分布等等。如果你只需要掌握一个的话，那肯定是正态分布。

正态分布（Normal Distribution），也叫高斯分布（Gaussian Distribution）。
在这个公式中有两个参数,μ表示均值，σ表示方差。从这个图可以看出，越靠近中心点μ，出现的概率越高，而随着渐渐远离μ，出现的概率先是加速下降，然后减速下降，直到趋近于 0。蓝色区域上的数字，表示了这个区域的面积，也就是数据取值在这个范围内的概率。例如，数据取值在[-1σ, μ]之间的概率为 34.1%。不过最实用的还是一元标准正态分布，这种分布的μ为 0，σ为 1。

期望值:
也叫数学期望，是每次随机结果的出现概率乘以其结果的总和。如果我们把每种结果的概率看作权重，那么期望值就是所有结果的加权平均值。它在我们的生活中十分常见，例如计算多个数值的平均值，其实就是求期望值，只不过我们假设每个数值出现的概率是相同的。

一个问题只要满足两个要素，我们就可以考虑使用期望值：第一个要素，在这个问题中可能出现不同的情况，而且各种情况的出现满足了一定的概率分布；第二个要素，每种情况都对应一个数值，这个数值代表了具体的应用含义。


对于离散型随机变量，通过联合概率 P(x, y) 在 y 上求和，就可以得到 P(x)，这个 P(x) 就是边缘概率（Marginal Probability）。对于连续型随机变量，我们可以通过联合概率 P(x, y) 在 y 上的积分，推导出边缘概率 P(x)。

条件概率也是由多个随机变量决定，但是和联合概率不同的是，它计算了给定某个（或多个）随机变量的情况下，另一个（或多个）随机变量出现的概率，其概率分布叫做条件概率分布。给定随机变量 x，随机变量 y 的条件概率使用 P(y | x) 表示。

联合概率是条件概率和概率的乘积，采用通用的公式来表达就是：
P(x, y) = P(x | y)* P(y)
P(x, y) = P(y | x)* P(x)

当x, y这二个随机变量是相互独立的时候，下面这个公式才成立：
P(x, y) = P(x)* P(y)
因为在x,y相互独立时，P(x | y) = P(x)
那么：P(x, y) = P(x | y)* P(y) = P(x)* P(y)