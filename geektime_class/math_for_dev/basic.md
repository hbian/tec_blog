## Binary
### 向左移位
二进制 110101 向左移一位，就是在末尾添加一位 0，因此 110101 就变成了1101010
如果将 1101010 换算为十进制，就是 106，你有没有发现，106 正好是 53 的 2 倍。所以，我们可以得出一个结论：二进制左移一位，其实就是将数字翻倍.

数字溢出，就是二进制数的位数超过了系统所指定的位数。目前主流的系统都支持至少 32 位的整型数字,如果进行左移操作的二进制已经超出了32位，左移后数字就会溢出，需要将溢出的位数去除。

### 向右移位
二进制 110101 向右移一位，就是去除末尾的那一位，因此 110101 就变成了 11010（最前面的 0 可以省略）。我们将 11010 换算为十进制，就是 26，正好是 53 除以 2 的整数商。所以二进制右移一位，就是将数字除以 2 并求整数商的操作。

### 位的或
逻辑“或”的意思是，参与操作的位中只要有一个位是 1，那么最终结果就是 1，也就是“真”。如果我们将二进制110101和100011的每一位对齐，进行按位的“或”操作，就会得到 110111。
```
110101
or
100011
=
110111
```

### 位的与
逻辑“与”的操作,“与”的意思是，参与操作的位中必须全都是 1，那么最终结果才是 1（真），否则就为 0（假）。如果我们将二进制 110101 和 100011 的每一位对齐，进行按位的“与”操作，就会得到 100001。
```
110101
and
100011
=
100001
```

### 位的异或
逻辑“异或”和“或”有所不同，它具有排异性，也就是说如果参与操作的位相同，那么最终结果就为 0（假），否则为 1（真）。所以，如果要得到1，参与操作的两个位必须不同，这就是此处“异”的含义。我们将二进制110101和100011的每一位对齐，进行按位的“异或”操作，可以得到结果是 10110
```
110101
xor ^
100011
=
010110
```

## 取余 Mod
* 余数总是在一个固定的范围内.
* 同余定理：就是两个整数 a 和 b，如果它们除以正整数m得到的余数相等，我们就可以说 a 和 b 对于模 m 同余。

利用这二个特性，同余定理就可以用来分类的。我们有无穷多个整数，那怎么能够全面、多维度地管理这些整数？同余定理就提供了一个思路。因为不管你的模是几，最终得到的余数肯定都在一个范围内。比如我们上面除以7，就得到了星期几；我们除以2，就得到了奇偶数。所以按照这种方式, 我们就可以把无穷多个整数分成有限多个类。
 
求余的过程就是个哈希函数，将任意长度的输入，通过哈希算法，压缩为某一固定长度的输出。

## Iterative Method
迭代法，简单来说，其实就是不断地用旧的变量值，递推计算新的变量值。
迭代法有具体应用,大体上，迭代法可以运用在以下几个方面：
* 求数值的精确或者近似解。典型的方法包括二分法（Bisection method）和牛顿迭代法（Newton’s method）。
* 在一定范围内查找目标值。典型的方法包括二分查找。
* 机器学习算法中的迭代。相关的算法或者模型有很多，比如 K- 均值算法（K-means clustering）、PageRank 的马尔科夫链（Markov chain）、梯度下降法（Gradient descent）等等。迭代法之所以在机器学习中有广泛的应用，是因为很多时候机器学习的过程，就是根据已知的数据和一定的假设，求一个局部最优解。而迭代法可以帮助学习算法逐步搜索，直至发现这种解。

迭代法的基本步骤：
* 确定用于迭代的步骤
* 建立迭代变量之间的递推关系
* 控制迭代过程

通过二分法求平方根
```
from __future__ import division

def get_square_root(n, delta_threshold, max_try):
    init_min = 0
    init_max = n
    for i in xrange(max_try):
        mid = (init_min + init_max) / 2
        square = mid * mid
        delta = abs((square / n) - 1)
        print "{} {} {} {} {}".format(init_min, init_max, mid, square, delta)
        if delta < delta_threshold:
            return mid
        else:
            if square > n:
                init_max = mid
            else:
                init_min = mid
    return mid

if __name__ == '__main__':
    print get_square_root(10, 0.0001, 20)
```


## 数学归纳法 Mathematical Induction

数论中，数学归纳法用来证明任意一个给定的情形都是正确的，也就是说，第一个、第二个、第三个，一直到所有情形，概不例外。
数学归纳法的一般步骤是这样的：
* 证明基本情况（通常是 n=1 的时候）是否成立；
* 假设 n=k−1 成立，再证明 n=k 也是成立的（k 为任意大于 1 的自然数）。

数学归纳法中的“归纳”是指的从第一步正确，第二步正确，第三步正确，一直推导到最后一步是正确的。数学归纳法并不是通过经验或样本的观察，总结出事物的普遍特征和规律。

递归调用的代码和数学归纳法的逻辑是一致的

迭代法是通过重复的步骤进行计算或者查询的。与此不同的是，数学归纳法在理论上证明了命题是否成立，而无需迭代那样反复计算，因此可以帮助我们节约大量的资源，并大幅地提升系统的性能。数学归纳法实现的运行时间几乎为 0。不过，数学归纳法需要我们能做出合理的命题假设，然后才能进行证明。虽然很多时候要做这点比较难，确实也没什么捷径。你就是要多做题，多去看别人是怎么解题的，自己去积累经验。

递归把计算交给计算机，归纳把计算交给人，前者是拿计算机的计算成本换人的时间，后者是拿人的时间换计算机的计算成本。迭代法在实际应用中，如果迭代层次过深 ，会导致各种问题(耗时\内存占用等) ，遇到这种情况可以总结规律， 使用数学归纳法将其简化。(代码中不再使用迭代 使用数学归纳总结出来的结果)

递归和循环其实都是迭代法的实现，而且在某些场合下，它们的实现是可以相互转化的。但是，对于某些应用场景，递归确很难被循环取代。
递归的核心思想和数学归纳法类似，并更具有广泛性。这两者的类似之处体现在：将当前的问题化解为两部分：一个当前所采取的步骤和另一个更简单的问题。
1. 一个当前所采取的步骤。这种步骤可能是进行一次运算（例如每个棋格里的麦粒数是前一格的两倍），或者做一个选择（例如选择不同面额的纸币），或者是不同类型操作的结合等等。
2. 另一个更简单的问题。经过上述步骤之后，问题就会变得更加简单一点。这里“简单一点”，指运算的结果离目标值更近（例如赏金的总额），或者是完成了更多的选择（例如纸币的选择）。而“更简单的问题”，又可以通过嵌套调用，进一步简化和求解，直至达到结束条件。我们只需要保证递归编程能够体现这种将复杂问题逐步简化的思想，那么它就能帮助我们解决很多类似的问题。

递归会使用计算机的函数嵌套调用。而函数的调用本身，就可以保存很多中间状态和变量值，因此极大的方便了编程的处理。

### 归并排序中的分治思想
分而治之（Divide and Conquer）的思想。分而治之，我们通常简称为分治。它的思想就是，将一个复杂的问题，分解成两个甚至多个规模相同或类似的子问题，然后对这些子问题再进一步细分，直到最后的子问题变得很简单，很容易就能被求解出来，这样这个复杂的问题就求解出来了。
实际上，分治主要就是用在将复杂问题转化为若干个规模相当的小问题上。分治思想通常包括问题的细分和结果的合并，正好对应于递归编程的函数嵌套调用和函数结果的返回。细分后的问题交给嵌套调用的函数去解决，而结果合并之后交由函数进行返回。所以，分治问题适合使用递归来实现。同时，分治的思想也可以帮助我们设计分布式系统和并行计算，细分后的问题交给不同的机器来处理，而其中的某些机器专门负责收集来自不同机器的处理结果，完成结果的合并。

### Mapreduce中的分治思想

1. 数据分割和映射分割是指将数据源进行切分，并将分片发送到 Mapper 上。映射是指 Mapper 根据应用的需求，将内容按照键 - 值的匹配，存储到哈希结构中。这两个步骤将大的数据集合切分为更小的数据集，降低了每台机器节点的负载，因此和分治中的问题分解类似。不过MapReduce采用了哈希映射来分配数据，而普通的分治或递归不一定需要。
2. 归约是指接受到的一组键值配对，如果是键内容相同的配对，就将它们的值归并。这和本机的递归调用后返回结果的过程类似。不过，由于哈希映射的关系，MapReduce 还需要洗牌的步骤，也就是将键 - 值的配对不断地发给对应的 Reducer 进行归约。普通的分治或递归不一定需要洗牌的步骤。 
3. 合并为了提升洗牌阶段的效率，可以选择减少发送到归约阶段的键-值配对。具体做法是在数据映射和洗牌之间，加入合并的过程，在每个 Mapper 节点上先进行一次本地的归约。然后只将合并的结果发送到洗牌和归约阶段。这和本机的递归调用后返回结果的过程类似。

## 排列和组合
从 n 个不同的元素中取出 m（1≤m≤n）个不同的元素，按照一定的顺序排成一列，这个过程就叫排列（Permutation）。当 m=n 这种特殊情况出现的时候，比如说，在田忌赛马的故事中，田忌的三匹马必须全部出战，这就是全排列（All Permutation）。

组合和排列有相似之处，都是从 n 个元素中取出若干个元素。不过，排列考虑了取出的元素它们之间的顺序，而组合无需考虑这种顺序。这是排列和组合最大的区别。因此，组合适合找到多个元素之间的联系而并不在意它们之间的先后顺序，例如多元文法中的多元组，这有利于避免不必要的数据保存或操作。具体到编程，组合和排列两者的实现非常类似。区别在于，组合并不考虑挑选出来的元素之间，是如何排序的。所以，在递归的时候，传入下一个嵌套调用函数的剩余元素，只需要包含当前被选元素之后的那些，以避免重复的组合。

组合的落地应用：
在自然语言处理中，我们需要用多元文化法把临近的几个单词合并起来成为一个词组。比如我可以把“red”和“bluetooth”合并为“red bluetooth”，还可以把“bluetooth”和“mouse”合并为“bluetooth mouse”。
普通的多元文法本身存在一个问题，那就是定死了每个元组内单词出现的顺序。例如，原文中可能出现的是“red bluetooth mouse”，可是用户在查询的时候可能输入的是“bluetooth mouse red”。这么输入肯定不符合语法，但实际上互联网上的用户经常会这么干。

解决的办法是：多个单词出现时，我并不关心它们的顺序（也就是不关心排列），而只关心它们的组合。因为无需关心顺序，就意味着我可以对多元组内的单词进行某种形式的标准化。即使原来的单词出现顺序有所不同，经过这个标准化过程之后，都会变成唯一的顺序。那么用户无论以哪种顺序进行搜索都会匹配到唯一的组合形式的词组。
在保存文章多元组和处理用户查询这两个阶段分别进行这种排序。这样既可以减少保存的数据量，同时可以减少查询的耗时。

## Dynamic Programming 动态规划
查询推荐。查询推荐的核心思想其实就是，对于用户的输入，查找相似的关键词并进行返回。而测量拉丁文的文本相似度，最常用的指标是编辑距离（Edit Distance）。

动态规划需要通过子问题的最优解，推导出最终问题的最优解，因此这种方法特别注重子问题之间的转移关系。我们通常把这些子问题之间的转移称为状态转移，并把用于刻画这些状态转移的表达式称为状态转移方程。很显然，找到合适的状态转移方程，是动态规划的关键。