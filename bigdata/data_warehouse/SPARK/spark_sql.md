RDD可以理解为是一条条数据组成的一维表，而DataFrame是每一行数据都有共同清晰的列划分的二维表。RDD是整个Spark平台的存储、计算以及任务调度的逻辑基础，更具有通用性，适用于各类数据源，而DataFrame是只针对结构化数据源的高层数据抽象，其中在DataFrame对象的创建过程中必须指定数据集的结构信息（Schema），所以DataFrame生来便是具有专用性的数据抽象，只能读取具有鲜明结构的数据集。

左侧的RDD[Person]虽然以Person类为类型参数，但Spark平台本身并不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得Spark SQL可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame多了数据的结构信息，即schema。RDD是分布式的Java对象的集合，DataFrame则是分布式的Row对象的集合。DataFrame除了提供了比RDD更丰富的算子操作以外，更重要的特点是利用已知的结构信息来提升执行效率、减少数据读取以及执行计划的优化，比如filter下推、裁剪等。

正是由于RDD并不像DataFrame提供详尽的结构信息，所以RDD提供的API功能上并没有像DataFrame强大丰富且自带优化，所以又称为Low-level API，相比之下，DataFrame被称为high-level的抽象，其提供的API类似于SQL这种特定领域的语言（DSL）来操作数据集。


### Hive表与Parquet文件的Schema转化兼容
从表Schema处理的角度对比Hive和Parquet，有两个区别：Hive区分大小写，Parquet不区分大小写。Hive允许所有的列为空，而Parquet不允许所有的列全为空。由于这两个区别，当将Hive metastore Parquet表转换为Spark SQL Parquet表时，需要将Hivemetastore schema和Parquet schema进行一致化。一致化规则如下：这两个schema中的同名字段必须具有相同的数据类型。一致化后的字段必须为Parquet的字段类型。这个规则同时也解决了空值的问题。一致化后的schema只包含Hive metastore中出现的字段。忽略只出现在Parquet schema中的字段。只在Hive metastore schema中出现的字段设为nullable字段，并加到一致化后的schema中。